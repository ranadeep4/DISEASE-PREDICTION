# Disease Prediction System

A machine learning-based disease prediction system that uses processed datasets from EDA notebook.

## ðŸ“ Project Structure

```
DISEASE_PREDICTION/
â”œâ”€â”€ content/                          # Original datasets
â”‚   â”œâ”€â”€ dataset.csv
â”‚   â”œâ”€â”€ Symptom-severity.csv
â”‚   â”œâ”€â”€ symptom_Description.csv
â”‚   â””â”€â”€ symptom_precaution.csv
â”œâ”€â”€ data/processed/                   # Processed datasets (from EDA notebook)
â”‚   â”œâ”€â”€ processed_dataset.csv
â”‚   â”œâ”€â”€ symptoms_list.csv
â”‚   â”œâ”€â”€ disease_distribution.csv
â”‚   â””â”€â”€ ...
â”œâ”€â”€ model/                           # Trained models
â”œâ”€â”€ src/                             # Source code
â”‚   â”œâ”€â”€ utils.py                     # Utility functions
â”‚   â”œâ”€â”€ inference.py                 # Inference functions
â”‚   â”œâ”€â”€ train.py                     # Training functions
â”‚   â””â”€â”€ models.py                    # Model definitions
â”œâ”€â”€ notebooks/                       # Jupyter notebooks
â”‚   â””â”€â”€ optimized_eda_preprocessing.ipynb
â”œâ”€â”€ app/                            # FastAPI application
â”‚   â””â”€â”€ app.py                     # Main API file
â””â”€â”€ requirements.txt
```

## ðŸš€ Quick Start

### Step 1: Run EDA Notebook
First, run the EDA notebook to create processed datasets:

```bash
# Open the notebook and run all cells
notebooks/optimized_eda_preprocessing.ipynb
```

This will create:
- `data/processed/processed_dataset.csv` - Main dataset with one-hot encoding
- `data/processed/symptoms_list.csv` - List of all symptoms
- `data/processed/disease_distribution.csv` - Disease information
- And other processed files

### Step 2: Train the Model
Run the training script:

```bash
python src/train.py
```

This will:
- Load the processed datasets
- Train multiple models (RandomForest, LogisticRegression, SVC, etc.)
- Select the best model based on cross-validation
- Save the model and symptoms list

### Step 3: Run the API
Start the FastAPI server:

```bash
python app/app.py
```

Then visit:
- API Documentation: http://127.0.0.1:8000/docs
- Health Check: http://127.0.0.1:8000/health
- Predict Disease: http://127.0.0.1:8000/predict

## ðŸ”§ Key Features

### 1. No DataFrame Fragmentation
The EDA notebook uses matrix-based one-hot encoding instead of adding columns one by one.

### 2. Simple Features
- `total_symptoms`: How many symptoms each patient has
- `symptom_percentage`: Percentage of symptoms (0-100%)

### 3. Clean API
- `/health` - Check system health
- `/symptoms` - Get available symptoms
- `/diseases` - Get available diseases
- `/predict` - Predict disease from symptoms

### 4. Multiple Models
Trains and compares:
- RandomForest
- LogisticRegression
- SVC
- KNeighbors
- DecisionTree

## ðŸ“ API Usage

### POST /predict
```json
{
  "symptoms": ["fever", "cough", "fatigue"],
  "model_name": "randomforest"
}
```

### GET /predict/fever,cough,fatigue
Simple GET request for testing.

## ðŸŽ¯ Example Workflow

1. **Run EDA notebook** â†’ Creates processed datasets
2. **Run training** â†’ Creates trained model
3. **Start API** â†’ Ready for frontend integration

## ðŸ” Troubleshooting

### "Processed datasets not found"
Run the EDA notebook first to create processed datasets.

### "Model not found"
Run `python src/train.py` to train the model.

### Import errors
Make sure all dependencies are installed:
```bash
pip install -r requirements.txt
```

## ðŸ“ˆ Performance

- **No DataFrame warnings** - Matrix-based encoding
- **Fast training** - Uses processed datasets
- **Accurate predictions** - Multiple model comparison
- **Clean API** - FastAPI with automatic documentation

## ðŸŽ‰ Benefits

1. **Simplified workflow** - Clear step-by-step process
2. **No warnings** - Optimized data processing
3. **Better performance** - Efficient feature engineering
4. **Clean code** - Removed unnecessary functions
5. **Easy integration** - Simple API endpoints

## ðŸ“Š What Changed

### Before (Complex):
- Multiple preprocessing functions
- DataFrame fragmentation warnings
- Complex feature engineering
- Multiple file formats

### After (Simple):
- Uses processed datasets from EDA notebook
- No DataFrame fragmentation warnings
- Simple feature engineering (total_symptoms, symptom_percentage)
- Clean, organized file structure

The system is now much simpler and more efficient! ðŸš€

## ðŸŒ API Endpoints

### Health Check
```http
GET /health
```

### Get Available Symptoms
```http
GET /symptoms
```

### Get Available Diseases
```http
GET /diseases
```

### Get Model Information
```http
GET /model-info
```

### Predict Disease
```http
POST /predict
Content-Type: application/json

{
  "symptoms": ["fever", "cough", "fatigue"]
}
```

**Response:**
```json
{
  "disease": "Common Cold",
  "confidence": 0.85,
  "all_probabilities": {
    "Common Cold": 0.85,
    "Flu": 0.12,
    "Bronchitis": 0.03
  },
  "valid_symptoms": ["fever", "cough", "fatigue"],
  "invalid_symptoms": [],
  "total_symptoms_checked": 132
}
```

### Batch Prediction
```http
POST /predict-batch
Content-Type: application/json

{
  "symptom_sets": [
    ["fever", "cough"],
    ["headache", "nausea"]
  ]
}
```

## ðŸ”§ Integration with Your MERN App

### Frontend (React) Example

```javascript
// Function to call the disease prediction API
const predictDisease = async (symptoms) => {
  try {
    const response = await fetch('https://your-disease-api.onrender.com/predict', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({ symptoms })
    });
    
    const result = await response.json();
    return result;
  } catch (error) {
    console.error('Error predicting disease:', error);
    throw error;
  }
};

// Usage in your React component
const handleSymptomSubmit = async (selectedSymptoms) => {
  try {
    const prediction = await predictDisease(selectedSymptoms);
    setPredictionResult(prediction);
  } catch (error) {
    setError('Failed to get prediction');
  }
};
```

### Backend (Node.js/Express) Example

```javascript
// Function to call the disease prediction API from your backend
const predictDisease = async (symptoms) => {
  try {
    const response = await fetch('https://your-disease-api.onrender.com/predict', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({ symptoms })
    });
    
    return await response.json();
  } catch (error) {
    console.error('Error calling disease prediction API:', error);
    throw error;
  }
};

// Express route example
app.post('/api/disease-prediction', async (req, res) => {
  try {
    const { symptoms } = req.body;
    const prediction = await predictDisease(symptoms);
    res.json(prediction);
  } catch (error) {
    res.status(500).json({ error: 'Prediction failed' });
  }
});
```

## ðŸš€ Deployment on Render

1. **Connect your repository** to Render
2. **Create a new Web Service**
3. **Configure the service:**
   - **Build Command:** 
     ```bash
     pip install -r requirements.txt && cd src && python train.py
     ```
   - **Start Command:** 
     ```bash
     cd app && gunicorn app:app --bind 0.0.0.0:$PORT
     ```
4. **Deploy!**

The service will be available at `https://your-service-name.onrender.com`

## ðŸ“Š Model Performance

The Random Forest model achieves:
- **Accuracy:** ~95% on test data
- **Supports:** 132 symptoms and 41 diseases
- **Prediction time:** < 100ms per request

## ðŸ› ï¸ Development

### Adding New Symptoms/Diseases

1. Update the dataset in `content/data.csv`
2. Retrain the model: `cd src && python train.py`
3. Redeploy the service

### Customizing the Model

Edit `src/train.py` to:
- Change the algorithm (SVM, Neural Network, etc.)
- Adjust hyperparameters
- Add feature engineering
- Implement cross-validation

### Local Development

```bash
# Install dependencies
pip install -r requirements.txt

# Train model
cd src && python train.py

# Start development server
cd app && python app.py

# Test the API
curl -X POST http://localhost:5000/predict \
  -H "Content-Type: application/json" \
  -d '{"symptoms": ["fever", "cough"]}'
```

## ðŸ”’ Security Considerations

- The API is stateless and doesn't store patient data
- All predictions are made in-memory
- Consider adding authentication if needed
- Use HTTPS in production

## ðŸ“ License

This project is open source and available under the MIT License.

## ðŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ðŸ“ž Support

If you encounter any issues:
1. Check the API health endpoint: `GET /health`
2. Verify the model is loaded: `GET /model-info`
3. Check the logs for error messages
4. Ensure all dependencies are installed correctly 